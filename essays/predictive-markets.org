#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../assets/style.css" />
#+OPTIONS: ^:nil

* problem
  Arriving at a good system design requires a few things:
  1. motivation, the programmer(s) must be motivated to design a good system
  2. experience, the programmer(s) must be capable of designing a good system
  3. foreknowledge, the programmer(s) must know enough about the project/goal/road-map
     to design a system well.

  We focus here on the third requirement,
  noting that we may in part or whole be addressing the second as well.
  We leave "good system design" abstract for the moment.

  In this case, even experts can't always predict how a
  system will need to change during the course of its construction.
  This might be due to a lack experience, time, or domain expertise.
  In any case, this makes designing a system difficult.
  If the choices one makes turn out to be incorrect the original effort spent
  designing the system and implementing it for that design was wasted in part
  and more effort must be expended to align to the "right" design.

  We need a crystal ball! ... or at least a rough approximation.

* predictive markets
  We will construct our crystal ball from a large collection of people
  willing to bet money on how and when a system will change.
  That is we will leverage the wisdom of the crowd motivated by money
  to "divine" future system changes.

  The scheme proceeds as follows:

  1. Contracts will be sold on an exchange.
  2. Each contract has a duration, portion of the design, and type.
  3. Each pays unit value if the design changes within the time period, zero o/w.

  The cost of purchasing a contract on the exchange represents
  the participant's prediction of the probability of change
  for the targeted portion of the design before the time period is up.
  That is, a participant who thinks that there is a 70% change a design feature
  will change should be willing to pay 70 cents for that contract (expected value).

  With this information in hand the programmer can evaluate their module boundaries for flaws.
  In a way you might see this as hyper motivated code review.

* example
  Consider the circular shift procedure from the first modularization
  from the Parnas paper.

  Parnas, participating in the market, knows that there are many reasons that
  the first modularization might change. He's so sure he's willing to spend nearly
  the contract pay-out since he'll make a dollar for each contract with near
  certainty.

  We might convey the change probability as a number or even a color in the code.

  #+begin_src ruby
  def shift(lines) # [0.8 (month)]
    # ...
  end
  #+end_src

* design decisions
  It's worth considering issuing contracts on a design document and not the code.
  This might harness the crowd to review higher level concepts without getting bogged
  down finding bugs or typos. For example, if a programmer misspells a variable name it's
  fairly sure that the enclosing module will be changed but nothing interesting
  is learned about design.

  Along the same lines, what constitutes a change meaningful enough to trigger
  a pay-out on the contract? Maybe if the tests change or the input/output relation?

* ad-hoc contracts
  In many cases it may be advantageous to allow users to issue contracts based on
  many different criteria beyond dates and changes. For example, asking generally whether
  a method has a bug in it would be one way to quickly get many eyes on a method. Further,
  interested crowds may wish to generate their own contracts if they find something of
  note not covered by the programmers.

* further examples
  - storing time series data in a sql database, will change with scaling
  - a poorly normalized database, will change with pain over time
  - storing passwords in clear text, someone will notice and change
  - functionality in controller methods, fat models convention, testing

* problems
  - "insider trading", programmer gaming the system
